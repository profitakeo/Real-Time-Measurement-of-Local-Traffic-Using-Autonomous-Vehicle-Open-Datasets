{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic Calculation (Waymo Open Dataset).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM1plOXzvcp6qfTLiUOXmAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profitakeo/Real-Time-Measurement-of-Local-Traffic-Using-Autonomous-Vehicle-Open-Datasets/blob/master/Traffic_Calculation_(Waymo_Open_Dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pVhOfzLx9us"
      },
      "source": [
        "# Measuring Traffic using Waymo Open Dataset\n",
        "\n",
        "- Dataset available at https://waymo.com/open/download/\n",
        "- Run using Google Colab: https://colab.research.google.com\n",
        "- Restart runtime before running\n",
        "- Based on [Waymo Open Dataset Tutorial](https://colab.research.google.com/github/waymo-research/waymo-open-dataset/blob/master/tutorial/tutorial.ipynb)\n",
        "- Found in [GitHub repository](https://github.com/profitakeo/Real-Time-Measurement-of-Local-Traffic-Using-Autonomous-Vehicle-Open-Datasets)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF6a5U35QFcG"
      },
      "source": [
        "## Install waymo_open_dataset package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxX_JIZrdKoR",
        "outputId": "a61c5b57-0973-406f-efc5-dfa16a6b4836"
      },
      "source": [
        "!rm -rf waymo-od > /dev/null\n",
        "!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
        "!cd waymo-od && git branch -a\n",
        "!cd waymo-od && git checkout remotes/origin/r1.0\n",
        "!pip3 install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'waymo-od'...\n",
            "remote: Enumerating objects: 884, done.\u001b[K\n",
            "remote: Total 884 (delta 0), reused 0 (delta 0), pack-reused 884\u001b[K\n",
            "Receiving objects: 100% (884/884), 14.19 MiB | 5.35 MiB/s, done.\n",
            "Resolving deltas: 100% (580/580), done.\n",
            "* \u001b[32mmaster\u001b[m\n",
            "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/master\n",
            "  \u001b[31mremotes/origin/master\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.0\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.0-tf1.15\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.0-tf2.0\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.2\u001b[m\n",
            "Note: checking out 'remotes/origin/r1.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at a66eb0a Merge branch 'master' into r1.0\n",
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.2.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxVSLH_OVfaF"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEt26SyRli7J",
        "outputId": "69b81ce4-6c37-4e6d-a477-af944014185d"
      },
      "source": [
        "%tensorflow_version 1.x # Change to tensorflow ver. 1\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x # Change to tensorflow ver. 1`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDQ1DPqwdfNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d037c2-2ed2-4489-d162-827f72d928d6"
      },
      "source": [
        "!pip3 install waymo-open-dataset\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from waymo_open_dataset.utils import range_image_utils\n",
        "from waymo_open_dataset.utils import transform_utils\n",
        "from waymo_open_dataset.utils import frame_utils\n",
        "from waymo_open_dataset import dataset_pb2 as open_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: waymo-open-dataset in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: tensorflow>=1.14.0 in /tensorflow-1.15.2/python3.6 (from waymo-open-dataset) (1.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.14.0->waymo-open-dataset) (1.15.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (1.33.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.14.0->waymo-open-dataset) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (0.35.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.14.0->waymo-open-dataset) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14.0->waymo-open-dataset) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.14.0->waymo-open-dataset) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14.0->waymo-open-dataset) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14.0->waymo-open-dataset) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.14.0->waymo-open-dataset) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14.0->waymo-open-dataset) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14.0->waymo-open-dataset) (3.4.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/waymo_open_dataset/utils/range_image_utils.py:59: The name tf.unsorted_segment_max is deprecated. Please use tf.math.unsorted_segment_max instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/waymo_open_dataset/utils/range_image_utils.py:226: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FsmRBp0WSAZ"
      },
      "source": [
        "## Mount Google Drive locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqnx3zUYcQZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f70959-26d2-41ed-adbe-2e557566abbf"
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1M1U1kCbm03"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXSW-qm4J3-O"
      },
      "source": [
        "### Showing camera image for a frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlCux-47J_lx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.max_open_warning': 0}) # Ignore warning about 20+ figures consuming memory\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def show_camera_image(camera_image, camera_labels, layout, cmap=None):\n",
        "  \"\"\"Show a camera image and the given camera labels\"\"\"\n",
        "\n",
        "  ax = plt.subplot(*layout)\n",
        "\n",
        "  # Draw the camera labels\n",
        "  for camera_labels in frame.camera_labels:\n",
        "    # Ignore camera labels that do not correspond to this camera\n",
        "    if camera_labels.name != camera_image.name:\n",
        "      continue\n",
        "\n",
        "    # Iterate over the individual labels\n",
        "    for label in camera_labels.labels:\n",
        "      # Draw the object bounding box\n",
        "      ax.add_patch(patches.Rectangle(\n",
        "        xy=(label.box.center_x - 0.5 * label.box.length,\n",
        "            label.box.center_y - 0.5 * label.box.width),\n",
        "        width=label.box.length,\n",
        "        height=label.box.width,\n",
        "        linewidth=1,\n",
        "        edgecolor='red',\n",
        "        facecolor='none'))\n",
        "\n",
        "  # Show/download camera image\n",
        "  plt.imshow(tf.image.decode_jpeg(camera_image.image), cmap=cmap)\n",
        "  plt.title(open_dataset.CameraName.Name.Name(camera_image.name))\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "  frame_img = 'frame' + str(i) + '.png'\n",
        "  plt.savefig('/content/Extracted_Data/' + frame_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPwN6p8HgkUK"
      },
      "source": [
        "### Convert frame data to DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNoD78U5MYdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca694fbe-a12c-4e18-a436-3109fb9a562e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import math\n",
        "\n",
        "def frame_to_dataframe(frame_data, frame_num):\n",
        "  \"\"\"Convert frame data to DataFrame\"\"\"\n",
        "\n",
        "  nltk_tokens = nltk.word_tokenize(str(frame_data)) # Tokenize frame data\n",
        "  df = pd.DataFrame()\n",
        "\n",
        "  # Search frame data\n",
        "  for i in range(len(nltk_tokens)):\n",
        "    # Append vehicle data obtained from laser\n",
        "    if nltk_tokens[i] == 'laser_labels':\n",
        "      laser_row = [[ nltk_tokens[i], nltk_tokens[i+47], nltk_tokens[i+6], nltk_tokens[i+9], nltk_tokens[i+12], \\\n",
        "                nltk_tokens[i+15], nltk_tokens[i+18], nltk_tokens[i+21], nltk_tokens[i+24], nltk_tokens[i+30],\\\n",
        "                nltk_tokens[i+33], nltk_tokens[i+36], nltk_tokens[i+39], nltk_tokens[i+43] ]]\n",
        "      df = df.append(laser_row, ignore_index=True)\n",
        "\n",
        "    # Append vehicle data obtained from camera\n",
        "    if nltk_tokens[i] == 'camera_labels':\n",
        "      if nltk_tokens[i+5] == 'labels':\n",
        "        camera_row = [[ nltk_tokens[i]+nltk_tokens[i+4], nltk_tokens[i+28], nltk_tokens[i+11], nltk_tokens[i+14],\\\n",
        "                    'NaN', nltk_tokens[i+17], nltk_tokens[i+20], 'NaN', 'NaN', 'NaN', 'NaN','NaN', 'NaN',\\\n",
        "                    nltk_tokens[i+24] ]]\n",
        "        df = df.append(camera_row, ignore_index=True)\n",
        "      elif nltk_tokens[i+5] == '}':\n",
        "        continue\n",
        "      for m in range(1, math.floor((len(nltk_tokens)-i)/31)):\n",
        "        if nltk_tokens[i+5+26*m] != 'labels':\n",
        "          break\n",
        "        elif nltk_tokens[i+5+26*m] == 'labels':\n",
        "          j = (i+5+26*m)\n",
        "          values = [[ nltk_tokens[i]+nltk_tokens[i+4], nltk_tokens[j+23], nltk_tokens[j+6], nltk_tokens[j+9],\\\n",
        "                'NaN', nltk_tokens[j+12], nltk_tokens[j+15], 'NaN', 'NaN', 'NaN', 'NaN','NaN', 'NaN',\\\n",
        "                nltk_tokens[j+19] ]];\n",
        "          df = df.append(values, ignore_index=True)\n",
        "  \n",
        "  # Formatting DataFrame\n",
        "  df.columns = ['device','iD', 'center_x', 'center_y', 'center_z', 'width', 'length', 'height', \\\n",
        "                'heading', 'speed_x', 'speed_y', 'accel_x', 'accel_y', 'type'];\n",
        "  df[['center_x', 'center_y', 'center_z', 'width', 'length', 'height', 'heading', 'speed_x', 'speed_y', 'accel_x', 'accel_y']] = \\\n",
        "   df[['center_x', 'center_y', 'center_z', 'width', 'length', 'height', 'heading', 'speed_x', 'speed_y', 'accel_x', 'accel_y']].astype('float64');\n",
        "  \n",
        "  # Convert DataFrame to .xslx\n",
        "  frame_xlsx ='frame' + str(frame_num) + '.xlsx'\n",
        "  df.to_excel(r'/content/Extracted_Data/' + frame_xlsx)\n",
        "  \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOvlXE74qP94"
      },
      "source": [
        "### Calculating AV speed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWT9Be1crBmZ"
      },
      "source": [
        "def find_AV_speed(df1, df2, frame_num):\n",
        "  \"\"\"Calculating AV speed\"\"\"\n",
        "\n",
        "  # Determine relative displacement of stationary sign object between 2 frames\n",
        "  is_sign = df1['type']=='TYPE_SIGN' # Filter signs from DF1\n",
        "  df_sign = df1[is_sign]\n",
        "  for i in range(len(df_sign)): # Search all signs in Frame 1\n",
        "    AV_dist_x_1 = df_sign['center_x'].iloc[i] # Find location of sign in Frame 1\n",
        "    AV_dist_y_1 = df_sign['center_y'].iloc[i]\n",
        "    is_sign_2 = df2['iD'] == df_sign.iloc[i][\"iD\"] # Go to DF2 and identify same sign\n",
        "    df_sign_2 = df2[is_sign_2]\n",
        "    if is_sign_2.any() == True: # Stop search if sign is also found in Frame 2\n",
        "      break\n",
        "  if df_sign_2.empty == True:\n",
        "    print('No signs in 2 consecutive frames. Calculation can no longer be performed!')\n",
        "  AV_dist_x_2 = df_sign_2['center_x'].iloc[0] # Obtain location of sign in Frame 2 \n",
        "  AV_dist_y_2 = df_sign_2['center_y'].iloc[0]\n",
        " \n",
        "  # Find speed of AV (m/s)\n",
        "  frame_rate = 10 # Hertz; given by Waymo Open Dataset\n",
        "  frame_len = 1/frame_rate\n",
        "  AV_speed_x =  -(AV_dist_x_2 - AV_dist_x_1) / frame_len\n",
        "  AV_speed_y =  -(AV_dist_y_2 - AV_dist_y_1) / frame_len\n",
        "\n",
        "  print(f'Frame {frame_num-1}: Sign x-coordinate = {AV_dist_x_1:.3f} m,\\\n",
        " Sign y-coordinate = {AV_dist_y_1:.3f} m\\n\\\n",
        " Frame {frame_num}: Sign x-coordinate = {AV_dist_x_2:.3f} m,\\\n",
        " Sign y-coordinate = {AV_dist_y_2:.3f} m,\\n\\\n",
        " AV x-speed = {AV_speed_x:.3f} m/s,\\\n",
        " AV y-speed = {AV_speed_y:.3f} m/s')\n",
        "  #print( round(AV_dist_x_1, 3), round(AV_dist_y_1,3), round(AV_dist_x_2, 3), round(AV_dist_y_2, 3),\n",
        "  #        round(AV_speed_x, 3), round(AV_speed_y, 3) )\n",
        "\n",
        "  # Find x-distance travelled by AV (m)\n",
        "  AV_dist_x = -(AV_dist_x_2 - AV_dist_x_1)\n",
        "\n",
        "  return AV_speed_x, AV_speed_y, AV_dist_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTGbHTVg0hKc"
      },
      "source": [
        "### Calculating traffic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv9_vNiypS6E"
      },
      "source": [
        "def calc_traffic(df1, df2, empty_DF, AV_cum_dist, AV_speed_x, AV_speed_y, AV_dist_x, frame_num):\n",
        "  \"\"\"Calculating traffic\"\"\"\n",
        "\n",
        "  # Filtering DataFrame before calculating\n",
        "  AV_len = 5.17 # metres; Waymo vehicle length\n",
        "  df_AV = {'device': 'laser_labels', 'iD': 'AV', 'center_x':0, 'center_y':0, 'center_z':0, \\\n",
        "           'width':np.NaN, 'length':AV_len, 'height':np.NaN, 'heading':0, 'speed_x':AV_speed_x,\\\n",
        "           'speed_y':AV_speed_y, 'accel_x':np.NaN, 'accel_y':np.NaN, 'type': 'TYPE_VEHICLE'} \n",
        "  df2 = df2.append(df_AV, ignore_index=True) # Append AV row data to DF2\n",
        "\n",
        "  is_veh = df2['type']=='TYPE_VEHICLE' # Show vehicle objects ...\n",
        "  df_veh = df2[is_veh]\n",
        "\n",
        "  is_laser = df_veh['device']=='laser_labels' # ... captured by LiDAR/laser ...\n",
        "  df_laser = df_veh[is_laser] \n",
        "\n",
        "  df_ord = df_laser.sort_values(by=['center_x']) # ... in ascending center_x values ...\n",
        "\n",
        "  road_width = 3.7 # metres; standard lane width given by U.S. Interstate Highway standards\n",
        "  in_lane = abs(df_ord['center_y']) <= road_width/2 # ... travelling in the same straight lane as the AV ...\n",
        "  df_lane = df_ord[in_lane]\n",
        "\n",
        "  heading_max = math.pi/4\n",
        "  fwd_dir = abs(df_lane['heading']) <= heading_max # ... and heading < Pi/4 rad.\n",
        "  df_fwd = df_lane[fwd_dir]\n",
        "\n",
        "  # Cumulative x-distance (metres) travelled by AV\n",
        "  cum_dist = {'AV Cumulative Distance (m)': [AV_dist_x]}\n",
        "  cum_dist_df = pd.DataFrame(cum_dist, columns = ['AV Cumulative Distance (m)'])\n",
        "  AV_cum_dist = AV_cum_dist.append(cum_dist_df) \n",
        "\n",
        "  # Calculating vehicle inputs\n",
        "  input = []  \n",
        "  for index, row in enumerate(df_fwd.itertuples()):\n",
        "    x_b = row.center_x - row.length*0.5*math.cos(row.heading) # Rear bumper x-coordinate\n",
        "    y_b = row.center_y - row.length*0.5*math.sin(row.heading) # Rear bumper y-coordinate\n",
        "    x_f = row.center_x + row.length*0.5*math.cos(row.heading) # Front bumper x-coordinate\n",
        "    y_f = row.center_y + row.length*0.5*math.sin(row.heading) # Front bumper y-coordinate\n",
        "    iD = row.iD\n",
        "    speed_tot = math.sqrt(row.speed_x**2+row.speed_y**2) # Defining total speed\n",
        "    center_x = row.center_x\n",
        "    length = row.length\n",
        "    input.append([iD, speed_tot, center_x, length, x_b, y_b, x_f, y_f])\n",
        "  df_0 = pd.DataFrame(input, columns=['iD', 'speed_tot', 'center_x', 'length','x_b', 'y_b', 'x_f', 'y_f'])\n",
        "  is_mov = abs(df_0['speed_tot']) > 0 # Filtering out stationary/parked vehicles defined by speed = 0 m/s\n",
        "  df_0 = df_0[is_mov]\n",
        "\n",
        "  # Shift rows for calculation between consecutive rows\n",
        "  # Source: https://stackoverflow.com/questions/42664418/referencing-to-the-next-index-in-iterrows\n",
        "  df_0['shifted_x_b'] = df_0['x_b'].shift(-1)\n",
        "  df_0['shifted_y_b'] = df_0['y_b'].shift(-1)\n",
        "  df_0['shifted_x_f'] = df_0['x_f'].shift(-1)\n",
        "  df_0['shifted_y_f'] = df_0['y_f'].shift(-1)\n",
        "\n",
        "  # Calculating more vehicle inputs\n",
        "  df_1 = []\n",
        "  for index, row in enumerate(df_0.itertuples()):\n",
        "    s = math.sqrt((row.shifted_x_b - row.x_f) **2 + (row.shifted_y_b - row.y_f) **2) # Spacing (front to rear bumper)\n",
        "    f = math.sqrt((row.shifted_x_f - row.x_f) **2 + (row.shifted_y_f - row.y_f) **2) # Spacing (front to front bumper)\n",
        "    h = f / row.speed_tot # Headway\n",
        "    df_1.append([s,f,h])\n",
        "  df_1 = pd.DataFrame(df_1, columns=['s', 'f', 'h'])\n",
        "  df_2 = pd.concat([df_0, df_1], axis=1)\n",
        "  df_3 = df_2.drop(columns=['shifted_x_b', 'shifted_y_b', 'shifted_x_f', 'shifted_y_f']) # Removed shifted columns\n",
        "\n",
        "  # Calculating traffic metrics\n",
        "  if df_3['h'].sum() == 0:\n",
        "    q_flow = ''\n",
        "  elif df_3['h'].sum() != 0:\n",
        "    q_flow = len(df_3) / df_3['h'].sum() * 3600 # veh/hr/lane\n",
        "  if df_3['s'].sum() == 0:\n",
        "    k_density = ''\n",
        "  elif df_3['s'].sum() != 0:\n",
        "    k_density = len(df_3) / df_3['s'].sum() * 1000 # veh/km/lane\n",
        "  v_avgspeed = df_3['speed_tot'].mean() * 3.6 # km/h\n",
        "  d_framelenx = (df_3['center_x'].max() + df_3['length'][df_3['center_x'].idxmax()]*0.5)- \\\n",
        "    (df_3['center_x'].min() - df_3['length'][df_3['center_x'].idxmin()]*0.5) # Distance between first/last vehicle\n",
        "  \n",
        "  frame_rate = 10 # Hertz\n",
        "  final_data = {'q (veh/h)': [q_flow], \\\n",
        "                'k (veh/km)': [k_density], \\\n",
        "                'v (km/h)':[v_avgspeed], \\\n",
        "                'd (Analysis Distance in m)': [d_framelenx], \\\n",
        "                'x (AV Distance in m)': [AV_dist_x], \\\n",
        "                'Frame': [frame_num], \\\n",
        "                'Time (s)': [(frame_num-1)/frame_rate], \\\n",
        "                'AV Cumulative Distance (m)': [AV_cum_dist.sum().sum()], \\\n",
        "                'Predicted q': [k_density*v_avgspeed], \\\n",
        "                'Actual vs. Predicted q (% difference)': [(k_density*v_avgspeed-q_flow)/q_flow*100]}\n",
        "  final_data = pd.DataFrame(final_data, columns = ['q (veh/h)', \\\n",
        "                                                   'k (veh/km)', \\\n",
        "                                                   'v (km/h)', \\\n",
        "                                                   'd (Analysis Distance in m)', \\\n",
        "                                                   'x (AV Distance in m)', \\\n",
        "                                                   'Frame', \\\n",
        "                                                   'Time (s)', \\\n",
        "                                                   'AV Cumulative Distance (m)', \\\n",
        "                                                   'Predicted q', \\\n",
        "                                                   'Actual vs. Predicted q (% difference)'])\n",
        "  final_data = empty_DF.append(final_data, ignore_index = True)\n",
        "  return final_data, AV_cum_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKDjJzrTGtnS"
      },
      "source": [
        "## Calculate traffic for all frames\n",
        "\n",
        "Before running:\n",
        "- Download .tfrecord files from [Waymo Open Dataset](https://waymo.com/open/download/) & upload to Google Drive\n",
        "- Create new folder 'Extracted_Data' under /content\n",
        "- Ensure file name and start/end frame are set correctly\n",
        "- To avoid inactivity, open console (ctrl+shift+i OR command+option+i) and run [function](https://medium.com/p/717b88a128c0/responses/show) shown below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlKvmqLIIi3Z"
      },
      "source": [
        "#function ConnectButton(){\n",
        "#    console.log(\"Connect pushed\")\n",
        "#    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "#}\n",
        "#setInterval(ConnectButton,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "29uZtYLJBx2r"
      },
      "source": [
        "# Parameters\n",
        "j = 1 # Start frame; min = 1\n",
        "k = 200 # End frame; max = 200\n",
        "FILENAME = '/gdrive/My Drive/Colab Notebooks/training_0002.tar/segment-11392401368700458296_1086_429_1106_429_with_camera_labels.tfrecord'\n",
        "\n",
        "# Initialising\n",
        "i = 0 # Frame count; initialise as 0\n",
        "i2 = 1 # Frame pair count; initialise as 1\n",
        "final_data_append = pd.DataFrame()\n",
        "AV_cum_dist_append = pd.DataFrame()\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
        "for data in dataset:\n",
        "\n",
        "  i += 1 # Count number of frames\n",
        "\n",
        "  if i<=j-1:\n",
        "    continue\n",
        "  frame = open_dataset.Frame()\n",
        "  frame.ParseFromString(bytearray(data.numpy()))\n",
        "  plt.figure(figsize=(25, 20))\n",
        "\n",
        "  for index, image in enumerate(frame.images):\n",
        "    show_camera_image(image, frame.camera_labels, [3, 3, index+1])\n",
        "    if i2%2 != 0: # For 1st frame in pair (where index is odd), generate DF\n",
        "      df1 = frame_to_dataframe(frame, i)\n",
        "    elif i2%2 == 0: # For 2nd frame in pair (where index is even), generate DF\n",
        "      df2 = frame_to_dataframe(frame, i)\n",
        "      if (index % 5) == 0:\n",
        "        AV_speed_x, AV_speed_y, AV_dist_x = find_AV_speed(df1, df2, i)\n",
        "        final_data_append, AV_cum_dist_append = calc_traffic(df1, df2, final_data_append, \\\n",
        "                                         AV_cum_dist_append, AV_speed_x, \\\n",
        "                                         AV_speed_y, AV_dist_x, i)\n",
        "        final_data_xlsx ='final_data' + str(i) + '.xlsx'\n",
        "        final_data_append.to_excel(r'/content/Extracted_Data/' + final_data_xlsx, sheet_name='Raw')\n",
        "      else:\n",
        "        pass\n",
        "      df1=df2 # Assign 1st frame as 2nd frame\n",
        "      i2 += 1\n",
        " \n",
        "  i2 += 1\n",
        "\n",
        "  if i==k: \n",
        "    break\n",
        "\n",
        "# Download zip folder\n",
        "!zip -r /content/Extracted_Data/Extracted_Data.zip /content/Extracted_Data\n",
        "from google.colab import files\n",
        "files.download('/content/Extracted_Data/Extracted_Data.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT3_HUfZ2UOr"
      },
      "source": [
        "## Obtaining DataFrame for Birds Eye Visualisation\n",
        "\n",
        "Before running:\n",
        "- Ensure file name and start/end frame are set correctly\n",
        "- Upload files \"framei.xlsx\" (for i = 1, ... ,200), which were created from previous step, to relevant Google Drive folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "7CoVf0Yz2mOv",
        "outputId": "60789f13-5278-4b4e-c962-3d6e96b561db"
      },
      "source": [
        "# Parameters\n",
        "j = 1 # Start frame; min = 1\n",
        "k = 200 # End frame; max = 200\n",
        "\n",
        "# Initialising\n",
        "birds_eye = pd.DataFrame() \n",
        "\n",
        "for y in range(k-j+1):\n",
        "  FILENAME = '/gdrive/My Drive/Colab Notebooks/training_0002.tar/Frame Data (0002_11392) OK/frame' + str(y+1) + '.xlsx'\n",
        "  df = pd.read_excel(FILENAME)\n",
        "  df[['center_x', 'center_y', 'center_z', 'width', 'length', 'height', 'heading', 'speed_x', 'speed_y', 'accel_x', 'accel_y']]= \\\n",
        "    df[['center_x', 'center_y', 'center_z', 'width', 'length', 'height', 'heading', 'speed_x', 'speed_y', 'accel_x', 'accel_y']].astype('float64')\n",
        "  df = df.drop(df.columns[[0]],axis=1)\n",
        "\n",
        "  AV_len = 5.17 # metres; Waymo vehicle length\n",
        "  df_AV = {'device': 'laser_labels', 'iD': 'AV', 'center_x':0, 'center_y':0, \\\n",
        "           'center_z':0, 'width':np.NaN, 'length':AV_len, 'height':np.NaN, \\\n",
        "           'heading':0, 'speed_x':0, 'speed_y':0, 'accel_x':np.NaN, \\\n",
        "           'accel_y':np.NaN, 'type': 'TYPE_AV'} \n",
        "  df = df.append(df_AV, ignore_index=True) # Append AV row data to DF2\n",
        "\n",
        "  is_veh = df['device']=='laser_labels' # Filter for vehicles captured by LiDAR\n",
        "  df_veh = df[is_veh]\n",
        " \n",
        "  # Populating DataFrame\n",
        "  df_0 = [] \n",
        "  for index, row in enumerate(df_veh.itertuples()):\n",
        "    frame_num = y+1\n",
        "    iD = row.iD\n",
        "    center_x = row.center_x\n",
        "    center_y = row.center_y\n",
        "    heading = row.heading\n",
        "    length = row.length\n",
        "    type = row.type\n",
        "    df_0.append([frame_num, iD, center_x, center_y,  heading, length, type])\n",
        "  df_1 = pd.DataFrame(df_0, columns=['Frame','iD', 'center_x', 'center_y', 'heading', 'length', 'type'])\n",
        "  birds_eye = birds_eye.append(df_1, ignore_index=True)\n",
        "\n",
        "# Download zip folder\n",
        "birds_eye.to_excel(r'/content/Extracted_Data/' + 'birds_eye_data (complete).xlsx', sheet_name='Raw')\n",
        "!zip -r /content/Extracted_Data/Extracted_Data.zip /content/Extracted_Data\n",
        "files.download('/content/Extracted_Data/Extracted_Data.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/Extracted_Data/ (stored 0%)\n",
            "  adding: content/Extracted_Data/birds_eye_data (complete).xlsx (deflated 4%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_438c3551-10f2-4dcb-9d91-2d704d0515cb\", \"Extracted_Data.zip\", 706790)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yODBm6BByyjW"
      },
      "source": [
        "After running the last 2 steps, you should now have the following 2 files:\n",
        "- final_data200.xlsx\n",
        "-  birds_eye_data (complete).xlsx\n",
        "\n",
        "Use as input for the .R files in source [GitHub repository](https://github.com/profitakeo/Real-Time-Measurement-of-Local-Traffic-Using-Autonomous-Vehicle-Open-Datasets).\n",
        "\n"
      ]
    }
  ]
}